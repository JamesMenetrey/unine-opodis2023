{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_dict = {\n",
    "    'native-tls-hw-supp': 'Native TLS HW supp',\n",
    "    'native-tls': 'Native TLS no HW supp',\n",
    "    'native': 'Native (no TLS)',\n",
    "    'wasm': 'WASM (no TLS)',\n",
    "    'wasm-tls': 'WASM TLS',\n",
    "    'sgx': 'WASM SGX (no TLS)',\n",
    "    'sgx-tls': 'WASM SGX TLS',\n",
    "    'qos0': 'QoS 0',\n",
    "    'qos1': 'QoS 1',\n",
    "    'qos2': 'QoS 2',\n",
    "    'expected_delivered': 'Expected delivered messages / s',\n",
    "    'delivered_messages': 'Delivered messages / s',\n",
    "    'reliability': 'Delivery rate (%)',\n",
    "    'latency': 'Latency (s)',\n",
    "    'throughput': 'Throughput (Messages /s) [at min 95 % reliability]',\n",
    "    'timestamp' : 'Time [s]',\n",
    "    'messages' : 'Messages / s',\n",
    "}\n",
    "\n",
    "cases = ['native-tls', 'native-tls-hw-supp', 'native', 'wasm', 'wasm-tls', 'sgx', 'sgx-tls']\n",
    "cases_tls = ['native-tls', 'wasm-tls', 'sgx-tls']\n",
    "cases_no_tls = ['native', 'wasm', 'sgx']\n",
    "cases_native = ['native-tls', 'native-tls-hw-supp', 'native']\n",
    "\n",
    "cases = cases_tls\n",
    "\n",
    "machine = 'grassen-1'\n",
    "payload_size = None\n",
    "import_base_bath = 'data/' + machine + '/'\n",
    "if payload_size != None:\n",
    "    import_base_bath += payload_size + '/'\n",
    "\n",
    "export_base_path = 'export/' + machine + '/'\n",
    "if payload_size != None:\n",
    "    export_base_path += payload_size + '/'\n",
    "os.makedirs(export_base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_publishers = 64\n",
    "number_subscribers = 25\n",
    "message_dict = {}\n",
    "first_missing_ts_dict = {}\n",
    "min_latency = {}\n",
    "for case in cases:\n",
    "    publisher_df = pd.DataFrame()\n",
    "    msg_df = pd.DataFrame()\n",
    "    for i in range(number_publishers):\n",
    "        df = pd.read_csv(import_base_bath + 'results_' + case + '/' + str(i) + '.csv', sep = ';')\n",
    "        if len(df) > 0:\n",
    "            publisher_df = pd.concat([publisher_df, df])\n",
    "    \n",
    "    # only send events\n",
    "    publisher_df = publisher_df[publisher_df['event'] == 3]\n",
    "    publisher_df = publisher_df.sort_values(by=['timestamp']).rename(columns={'timestamp': 'timestamp_send'})\n",
    "    publisher_df = publisher_df.drop(columns=['event'])\n",
    "\n",
    "    subscriber_df = pd.DataFrame()\n",
    "    for i in range(number_subscribers):\n",
    "        df = pd.read_csv(import_base_bath + 'results_' + case + '/' + str(i + number_publishers) + '.csv', sep = ';')\n",
    "        subscriber_df = pd.concat([subscriber_df, df])\n",
    "        df = publisher_df.merge(df, on='payload', how='left')\n",
    "        df = df.rename(columns={'timestamp': 'timestamp_receive'})\n",
    "        msg_df = pd.concat([msg_df, df])\n",
    "\n",
    "    \n",
    "    # only receive events\n",
    "    subscriber_df = subscriber_df[subscriber_df['event'] == 9]\n",
    "    subscriber_df = subscriber_df.sort_values(by=['timestamp']).rename(columns={'timestamp': 'timestamp_receive'})\n",
    "    subscriber_df = subscriber_df.drop(columns=['event'])\n",
    "    \n",
    "    print('Case: ' + case)\n",
    "    print('Number of received messages: ' + str(len(subscriber_df)))\n",
    "    print('Number of sent messages: ' + str(len(publisher_df)))\n",
    "\n",
    "    \n",
    "    df = pd.merge(subscriber_df, publisher_df, on='payload', how='outer')\n",
    "    print('Number of lost messages: ' + str(len(msg_df) - len(subscriber_df)))\n",
    "    missing = msg_df[msg_df['timestamp_receive'].isnull()]\n",
    "    first_missing_ts_dict[case] = missing['timestamp_send'].min()\n",
    "    print('\\n')\n",
    "    df = df.drop(columns=['payload'])\n",
    "\n",
    "    df['latency'] = df['timestamp_receive'] - df['timestamp_send']\n",
    "    min_latency[case] = df['latency'].min()\n",
    "\n",
    "    message_dict[case] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "f = open(export_base_path + 'readme.txt', 'w')\n",
    "f.write('This folder contains the results of the case \"publisher scaling\".\\n')\n",
    "f.write('In this case, the number of subscribers and the message rate is fixed.\\n')\n",
    "f.write('The number of publishers scales from 1 to 64 at en exponential rate (2^i)\\n')\n",
    "f.write('Every case runs for 60 seconds. Afterwards the number is increased. Note, that the broker is not restarted inbetween.\\n\\n')\n",
    "f.write('The parameters used are as follows:\\n')\n",
    "f.write('  - Number of subscribers: ' + str(number_subscribers) + '\\n')\n",
    "f.write('  - Message rate: 5 messages / s\\n')\n",
    "f.write('  - Size of Payload: 16Kb random data\\n')\n",
    "f.write('  - QoS: 0\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_dict = {}\n",
    "for case in cases:\n",
    "    df = pd.read_csv(import_base_bath + 'results_' + case + '/orchestrator.csv', sep = ';')\n",
    "    # iterate through df\n",
    "    bins = pd.DataFrame(columns = ['bin', 'start', 'end', 'duration'])\n",
    "    for index, row in df.iterrows():\n",
    "        # add new bin\n",
    "        bins = bins.append({'bin': row['payload'], 'start': row['timestamp']}, ignore_index = True)\n",
    "\n",
    "        # check if bin is already in bins\n",
    "        if index > 0:\n",
    "            # update end time\n",
    "            bins.iloc[index-1]['end'] = row['timestamp']\n",
    "            # update duration\n",
    "            bins.iloc[index-1]['duration'] = bins.iloc[index-1]['end'] - bins.iloc[index-1]['start'] \n",
    "        \n",
    "        if index == len(df) - 1:\n",
    "            bins.iloc[index]['end'] = message_dict[case]['timestamp_receive'].max()\n",
    "            bins.iloc[index]['duration'] = bins.iloc[index]['end'] - bins.iloc[index]['start'] \n",
    "        \n",
    "    bin_dict[case] = bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    start_of_last = bin_dict[case].tail(1)['start'].values[0]\n",
    "    print(case)\n",
    "    print(first_missing_ts_dict[case] - start_of_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign every message to one of the bins\n",
    "for case in cases:\n",
    "    result_df = pd.DataFrame()\n",
    "    message_df = message_dict[case]\n",
    "    message_df['nb_publishers'] = 0\n",
    "    bin_df = bin_dict[case]\n",
    "    for index, row in bin_df.iterrows():\n",
    "        # get all messages which have send timestamp between start and end\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        message_df.loc[(message_df['timestamp_send'] >= start) & (message_df['timestamp_send'] < end), 'nb_publishers'] = row['bin']\n",
    "\n",
    "    message_df = message_df[message_df['nb_publishers'] != 0]\n",
    "\n",
    "    message_df_grouped = message_df.groupby(['nb_publishers']).max().reset_index()\n",
    "    min_latency_case = min_latency[case]\n",
    "    for index, row in message_df_grouped.iterrows():\n",
    "        # if the max latency is bigger than 1000 * min_latency, then drop all rows in message_df which have the same nb_publishers\n",
    "        if row['latency'] > 1000 * min_latency_case:\n",
    "            #message_df = message_df[message_df['nb_publishers'] != row['nb_publishers']]\n",
    "            # set the latency to 1000*min_latency for all messages with the same nb_publishers\n",
    "            #message_df.loc[message_df['nb_publishers'] == row['nb_publishers'], 'latency'] = 1000 * min_latency_case\n",
    "            print('Case: ' + case + ' - ' + str(row['nb_publishers']) + ' - ' + str(row['latency']))\n",
    "\n",
    "    message_dict[case] = message_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_latency = pd.DataFrame()\n",
    "for case in cases:\n",
    "    df = message_dict[case]\n",
    "    df['case'] = case\n",
    "    message_latency = pd.concat([message_latency, df])\n",
    "\n",
    "message_latency.to_csv(export_base_path + 'message_latency.csv')\n",
    "\n",
    "# write a description file for the export\n",
    "f = open('export/' + machine + '/message_latency.txt', 'w')\n",
    "f.write('This file contains for every message the observed latency.\\n')\n",
    "f.write('The first column is a index without any further meaning\\n')\n",
    "f.write('the other columns are as described below:\\n\\n')\n",
    "for col in message_latency.columns:\n",
    "    if(col == 'case'):\n",
    "        f.write(col + ': case of the measurement\\n')\n",
    "    if(col == 'latency'):\n",
    "        f.write(col + ': end to end latency for this given message in ms\\n')\n",
    "    if(col == 'nb_publishers'):\n",
    "        f.write(col + ': the number of publishers that published messages\\n')\n",
    "    if(col == 'timestamp_send'):\n",
    "        f.write(col + ': the timestamp of when the publisher sent the message\\n')\n",
    "    if(col == 'timestamp_receive'):\n",
    "        f.write(col + ': the timestamp of when the subscriber received the message\\n')\n",
    "\n",
    "f.write('\\n\\n')\n",
    "f.write('The following cases were measured:\\n')\n",
    "for case in cases:\n",
    "    f.write(case + ': ' + translation_dict[case] +'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_per_publishers = pd.DataFrame()\n",
    "for case in cases:\n",
    "    messages = message_dict[case]\n",
    "    messages = messages.dropna()\n",
    "    messages = messages.drop(columns=['timestamp_send', 'timestamp_receive', 'case'])\n",
    "    df = messages.groupby('nb_publishers').mean()\n",
    "    \n",
    "    df['case'] = case\n",
    "    df = df.reset_index()\n",
    "    latency_per_publishers = pd.concat([latency_per_publishers, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_per_publishers.to_csv(export_base_path + 'latency_per_publishers.csv')\n",
    "\n",
    "# write a description file for the export\n",
    "f = open('export/' + machine + '/latency_per_nb_publishers.txt', 'w')\n",
    "f.write('This file contains the average of the maximum latency of every message per number of publishers.\\n')\n",
    "f.write('The first column is a index without any further meaning\\n')\n",
    "f.write('the other columns are as described below:\\n\\n')\n",
    "for col in latency_per_publishers.columns:\n",
    "    if(col == 'case'):\n",
    "        f.write(col + ': case of the measurement\\n')\n",
    "    if(col == 'latency'):\n",
    "        f.write(col + ': mean latency of all single message latencies\\n')\n",
    "    if(col == 'nb_publishers'):\n",
    "        f.write(col + ': the number of publishers that published messages\\n')\n",
    "\n",
    "f.write('\\n\\n')\n",
    "f.write('The following cases were measured:\\n')\n",
    "for case in cases:\n",
    "    f.write(case + ': ' + translation_dict[case] +'\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_df = pd.DataFrame()\n",
    "for case in cases:\n",
    "    df = message_dict[case]\n",
    "    df = df.drop(columns=['timestamp_send', 'timestamp_receive'])\n",
    "    df['case'] = case\n",
    "    cdf_df = pd.concat([cdf_df, df])\n",
    "cdf_df = cdf_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = latency_per_publishers.rename(columns={'latency': 'Latency (ms)', 'nb_publishers': 'number of publishers'})\n",
    "df = df[df['number of publishers'] <= 30]\n",
    "sns.barplot(data=df, x='number of publishers', y='Latency (ms)', hue='case')\n",
    "plt.title('Average latency by number of publishers / s\\n['+ machine + ']')\n",
    "plt.xlabel('number of publishers')\n",
    "plt.ylabel('Latency (ms)')\n",
    "\n",
    "\n",
    "plt.savefig(export_base_path + 'latency_per_number_publishers.png', dpi=300, bbox_inches='tight', transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special graph\n",
    "df = latency_per_publishers.rename(columns={'latency': 'Latency (ms)', 'nb_publishers': 'number of publishers'})\n",
    "df['message rate'] = df['number of publishers'] * 50\n",
    "df = df[df['number of publishers'] <= 30]\n",
    "sns.barplot(data=df, x='message rate', y='Latency (ms)', hue='case')\n",
    "plt.title('Average latency by message rate\\n['+ machine + ']')\n",
    "plt.xlabel('message rate')\n",
    "plt.ylabel('Latency (ms)')\n",
    "\n",
    "plt.savefig(export_base_path + 'latency_per_message_rate.png', dpi=300, bbox_inches='tight', transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = latency_per_publishers.rename(columns={'latency': 'Latency (ms)', 'nb_publishers': 'number of publishers'})\n",
    "#df = df[df['number of publishers'].isin([1, 2, 4, 8, 16, 32, 64])]\n",
    "df = df.reset_index(drop=True)\n",
    "sns.lineplot(data=df, x='number of publishers', y='Latency (ms)', hue='case')\n",
    "plt.title('Average latency by number of publishers / s\\n['+ machine + ']')\n",
    "plt.xlabel('number of publishers')\n",
    "plt.ylabel('Latency (ms)')\n",
    "\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlim(0, 60)\n",
    "\n",
    "plt.savefig(export_base_path + 'latency_per_number_publishers_lineplot.png', dpi=300, bbox_inches='tight', transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cdf_df.rename(columns={'latency': 'Latency (ms)', 'nb_publishers': 'number of publishers'})\n",
    "df = df[df['number of publishers'] <= 25]\n",
    "sns.boxplot(data=df, x='number of publishers', y='Latency (ms)', hue='case')\n",
    "plt.title('Average latency by number of publishers / s\\n['+ machine + ']')\n",
    "plt.xlabel('number of publishers')\n",
    "plt.ylabel('Latency (ms)')\n",
    "\n",
    "plt.savefig(export_base_path + 'latency_per_nb_publishers_whisker.png', dpi=300, bbox_inches='tight', transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read heap max\n",
    "heap_max = pd.DataFrame()\n",
    "for case in cases:\n",
    "    df = pd.read_csv(import_base_bath + 'results_' + case + '/heap_max.csv', sep = ';')\n",
    "    bin_df = bin_dict[case]\n",
    "    df['nb_publishers'] = 0\n",
    "    for index, row in bin_df.iterrows():\n",
    "        # get all messages which have send timestamp between start and end\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        df.loc[(df['timestamp'] >= start) & (df['timestamp'] < end), 'nb_publishers'] = row['bin']\n",
    "    \n",
    "    df = df[df['nb_publishers'] != 0]\n",
    "    df = df.groupby(['nb_publishers']).max()\n",
    "    df = df.reset_index()\n",
    "    df['case'] = case\n",
    "    heap_max = pd.concat([heap_max, df])\n",
    "df = heap_max\n",
    "#df = heap_max[heap_max['nb_publishers'].isin([1, 2, 4, 8, 16, 32, 64])]\n",
    "#df = df[df['case'].isin(['wasm-tls', 'sgx-tls'])]\n",
    "sns.barplot(data=df, x='nb_publishers', y='payload', hue='case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_publisher_values = cdf_df[\"nb_publishers\"].unique()\n",
    "toPlot = pd.DataFrame()\n",
    "for case in cases:\n",
    "    for nb_pub in nb_publisher_values:\n",
    "        df = cdf_df[(cdf_df[\"case\"] == case) & (cdf_df[\"nb_publishers\"] == nb_pub)]\n",
    "        df = df.sort_values(by=\"latency\")\n",
    "        df = df.reset_index(drop=True)\n",
    "        n = len(df)\n",
    "        df['cdf'] = (df.index + 1) / n\n",
    "        toPlot = pd.concat([toPlot, df])\n",
    "\n",
    "toPlot = toPlot.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through every value of nb_publishers and plot the cdf in a new plot\n",
    "# all plots together should be one figure (2 rows, 3 plots each row)\n",
    "for nb_pub in nb_publisher_values:\n",
    "    # reset the last plt object\n",
    "    plt.clf()\n",
    "    print(nb_pub)\n",
    "    df = toPlot[toPlot[\"nb_publishers\"] == nb_pub]\n",
    "    #df = df[df[\"case\"].isin(['native-tls', 'native-tls-hw-supp'])]\n",
    "    df = df.sort_values(by=\"latency\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    #sns.lineplot(data=df, x=\"latency\", y=\"cdf\", style=\"case\", dashes=False, markers=True)\n",
    "    sns.displot(data=df, x=\"latency\", hue=\"case\", kind=\"ecdf\")\n",
    "    plt.xlabel(\"Latency (ms)\")\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.title(\"CDF of latency for \" + str(nb_pub) + \" publishers\")\n",
    "    plt.savefig(export_base_path + '/cdf_latency_' + str(nb_pub) + '_publishers.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
